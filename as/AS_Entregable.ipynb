{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0KvvwSXcPxY"
   },
   "source": [
    "# DiploDatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElP7afRkcPxe"
   },
   "source": [
    "Presentamos un código creado como ejemplo de base para la competición.\n",
    "\n",
    "Deben:\n",
    "\n",
    "- Explorar los datos y aprender de ellos.\n",
    "- Probar diferentes modelos y ver cuáles ajustan mejor dado los datos.\n",
    "- **Obtener una accuracy mejor que la que se presenta en este ejemplo.**\n",
    "- Tratar de obtener la accuracy más alta posible!\n",
    "- Discutir la elección de modelo.\n",
    "\n",
    "El análisis exploratorio y el preprocesamiento de los datos queda a libertad de cada grupo y no deben quedarse con este simple ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QK117h0hcPxf"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# preprocesamiento de datos\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, \n",
    "    LabelEncoder, \n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "# aprendizaje automático supervisado\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    GridSearchCV, \n",
    "    StratifiedKFold, \n",
    "    cross_val_score, \n",
    "    cross_validate, \n",
    "    KFold, \n",
    "    LeaveOneOut, \n",
    "    LeavePOut,\n",
    ")\n",
    "# métricas\n",
    "from sklearn.metrics import (\n",
    "    recall_score, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "# modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVpt4_EGDhKE"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta correcta')\n",
    "    plt.xlabel('Etiqueta predicha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCCpYHKXd4jj"
   },
   "source": [
    "### Analisis exploratorio y visualizacion del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2h7Mc0dqkFDY"
   },
   "outputs": [],
   "source": [
    "# Conjunto de Train\n",
    "URL = 'https://drive.google.com/file/d/16SSOt06KitPEkAXQwfPyM16jojqCxwtl/view?usp=sharing'\n",
    "path = 'https://drive.google.com/uc?export=download&id='+URL.split('/')[-2]\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQPld6keBnbC"
   },
   "outputs": [],
   "source": [
    "# Conjunto de Test\n",
    "URL = 'https://drive.google.com/file/d/1EVGW3CQeKZjtkdusFIp9KjqF87rFl264/view?usp=sharing'\n",
    "path = 'https://drive.google.com/uc?export=download&id='+URL.split('/')[-2]\n",
    "test_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "R8C1jmaQrDhM",
    "outputId": "dc944a98-9592-475e-bf2f-dbc2a1e1ce07"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gm_3k59hMOmY",
    "outputId": "86a13ca9-658d-45e0-b1ca-0832b3a03fdb"
   },
   "outputs": [],
   "source": [
    "# Analizamos las columnas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nqmtg2egkIb_",
    "outputId": "8b35f03f-92a4-4170-82aa-12aa4b18771d"
   },
   "outputs": [],
   "source": [
    "# Analizamos la cantidad de datos por columna y si hay valores nulos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MOLlEYZKTqQ",
    "outputId": "4a29222b-c467-48ec-c263-1d0d86295ae6"
   },
   "outputs": [],
   "source": [
    "# Analizamos la cantidad de datos faltantes\n",
    "missing_values_count = df.isna().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_Uxf1xiettB"
   },
   "source": [
    "### Imputacion y transformacion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bugQterLcPxg"
   },
   "outputs": [],
   "source": [
    "# Extraemos nuestro target del resto de variables\n",
    "y = df.Transported\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6twc_68mtVz2"
   },
   "outputs": [],
   "source": [
    "# Para la Columna Destino cambiamos los nombres de las columnas\n",
    "dic_dest = {'TRAPPIST-1e' : 'Destination_TRAPPIST-1e',\n",
    "        '55 Cancri e' : 'Destination_55 Cancri e',\n",
    "        'PSO J318.5-22' : 'Destination_PSO J318.5-22',\n",
    "        np.nan : np.nan}\n",
    "X['Destination'] = X['Destination'].map(dic_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DI_01OpstapY"
   },
   "outputs": [],
   "source": [
    "# Hacemos un one hot (con get.dummies) dividiendo las categorias de destino\n",
    "x_dest = pd.get_dummies(X['Destination'])\n",
    "for i in range(len(x_dest)):\n",
    "    if (x_dest.iloc[i,0]+x_dest.iloc[i,1]+x_dest.iloc[i,2]) == 0:\n",
    "        x_dest.iloc[i,:] = x_dest.iloc[i,:].replace(0, np.nan)\n",
    "a = x_dest.columns\n",
    "X[a] = x_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BHR9ihhs5gW"
   },
   "outputs": [],
   "source": [
    "# Para la Columna HomePlanet cambiamos los nombres \n",
    "dic_planet = {'Earth' : 'HomePlanet_Earth',\n",
    "              'Europa' : 'HomePlanet_Europa',\n",
    "              'Mars' : 'HomePlanet_Mars',\n",
    "              np.nan : np.nan}\n",
    "X['HomePlanet'] = X['HomePlanet'].map(dic_planet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkEERhiVvrru"
   },
   "outputs": [],
   "source": [
    "# Hacemos un one hot dividiendo las categorias de HomePlanet\n",
    "x_home = pd.get_dummies(X['HomePlanet'])\n",
    "for i in range(len(x_dest)):\n",
    "    if (x_home.iloc[i,0]+x_home.iloc[i,1]+x_home.iloc[i,2]) == 0:\n",
    "        x_home.iloc[i,:] = x_home.iloc[i,:].replace(0, np.nan)\n",
    "a = x_home.columns\n",
    "X[a] = x_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDWhGKIkmnTZ"
   },
   "outputs": [],
   "source": [
    "# Separamos en tres columnas \"Cabin\"\n",
    "X[['Cabin_Deck','Cabin_Num','Cabin_Side']] = X['Cabin'].str.split('/',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMqG-m3n1Bzy"
   },
   "outputs": [],
   "source": [
    "# Hacemos encodig de variables categoricas que tienen un cierto orden\n",
    "Label_cols = ['VIP', 'CryoSleep', 'Cabin_Deck', 'Cabin_Side' ]\n",
    "for col in Label_cols:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2V6NbFLwfwm"
   },
   "outputs": [],
   "source": [
    "# Volvemos a  definir las variables nan para luego ser imputadas \n",
    "Label_col = ['VIP', 'CryoSleep', 'Cabin_Side' ]\n",
    "X[Label_col] = X[Label_col].replace(2, np.nan)\n",
    "X['Cabin_Deck'] = X['Cabin_Deck'].replace(8, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27OsbDiSzWlX"
   },
   "outputs": [],
   "source": [
    "# Limpiamos el dataset antes de imputar los valores faltantes\n",
    "X = X.drop(['Cabin', 'Destination', 'HomePlanet', 'Name', 'PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RN70GKTF2HvM",
    "outputId": "3b24461a-b8e6-49bc-f0c3-ba4f119ec285"
   },
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aktFrm6l4HEB",
    "outputId": "52e304d8-6878-4ffb-80a0-88f6e67cd669"
   },
   "outputs": [],
   "source": [
    "X['Cabin_Num'] = X['Cabin_Num'].astype(float)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "En8PUQW44kG6"
   },
   "outputs": [],
   "source": [
    "# Estandarizamos y escalamos los valores antes de imputar\n",
    "x_names = X.columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "w4KaMLtm3OM7",
    "outputId": "e5238f46-04ed-49cc-fc7b-3f521ffc1c8a"
   },
   "outputs": [],
   "source": [
    "# Imputamos todos los valores con knn imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "X_knn = X.copy()\n",
    "knn_imputer = KNNImputer(n_neighbors=9, weights=\"uniform\")\n",
    "X_knn = knn_imputer.fit_transform(X_knn)\n",
    "\n",
    "# Volvemos a convertirlo en DF\n",
    "X_knn = pd.DataFrame(X_knn, columns=x_names)\n",
    "X_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "9QuPWuAY1qPK",
    "outputId": "ca48b096-ef9f-418e-dc5b-6dd728ee0163"
   },
   "outputs": [],
   "source": [
    "X_knn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGNIo9-ComHN",
    "outputId": "261cef57-9f1a-4481-bf14-e4ace3239a12"
   },
   "outputs": [],
   "source": [
    "X_knn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "id": "F7m37X3n5txK",
    "outputId": "4cb8c935-a6db-493a-f558-fb425f6a48a1"
   },
   "outputs": [],
   "source": [
    "# Analizamos la correlación entre las variables\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(X_knn.corr(),annot=True,fmt='.2g')\n",
    "plt.title('Correlacion entre variables', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr2y3dSdjW-F"
   },
   "source": [
    " Con la caracteristica que más se correlaciona con nuestro target es CryoSleep, aunque es baja  al igual que el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0PYbVk07PTi",
    "outputId": "dbb63372-270f-43ab-ae8b-665053b2982b"
   },
   "outputs": [],
   "source": [
    "X_knn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naKRrJzmHHoG"
   },
   "outputs": [],
   "source": [
    "# Elimino mi target del resto del dataset\n",
    "X_knn = X_knn.drop('Transported', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRWz0-XNcPxj"
   },
   "outputs": [],
   "source": [
    "# Dividimos los datos para el entrenamiento y test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_knn, y, train_size=0.8, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "XuO5hLx352ll",
    "outputId": "c2963342-cb90-40cf-be64-baf3f9dcc0c9"
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFPLrj9-fJ_r"
   },
   "source": [
    "### Prueba con varios modelos de aprendisaje supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xrm509VyOGhE",
    "outputId": "952d2bf5-9959-4ad1-b5a5-431442fba0a8"
   },
   "outputs": [],
   "source": [
    "clfs =  [DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier(),\n",
    "        XGBClassifier(),\n",
    "        GaussianNB(),\n",
    "        LinearSVC()]\n",
    "\n",
    "names = ['Arbol de decisión',\n",
    "        'Random Forest', \n",
    "        'Regresión Logística',\n",
    "        'Perceptrón multicapa',\n",
    "        'XGBoost',\n",
    "        'Naive Bayes',\n",
    "        'SVM']\n",
    "\n",
    "trained_models = []\n",
    "accuracy_models = []\n",
    "for clf, name in zip(clfs, names):\n",
    "    print(name)\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_predictions = clf.predict(x_train)\n",
    "    accuracy = accuracy_score(y_train, train_predictions)\n",
    "    print(f\"Accuracy train {name}: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    test_predictions = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(f\"Accuracy test {name}: %.2f%%\" % (accuracy * 100.0))\n",
    "    trained_models.append(clf)    \n",
    "    accuracy_models.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0q1ukU7Du1"
   },
   "source": [
    "#### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrzWrj8__Pma"
   },
   "outputs": [],
   "source": [
    "param_grid_re = [{\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "    'C': [0.6 ,0.7, 0.8, 0.9, 0.5, 1],\n",
    "    'random_state' : [43],\n",
    "    'max_iter' : [100, 200, 1000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnYJ_Uz7ucJU",
    "outputId": "2818c930-ea4a-4bde-c6b4-dbe20429ef3f"
   },
   "outputs": [],
   "source": [
    "# Regresión Logística\n",
    "clf_re = LogisticRegression()\n",
    "cv_re = GridSearchCV(clf_re, param_grid_re, scoring='accuracy') \n",
    "cv_re.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rREtjK8X0016",
    "outputId": "13901f06-1c14-4ff2-a8cf-b37f39800ccc"
   },
   "outputs": [],
   "source": [
    "cv_re.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "hd7mfqzP00r0",
    "outputId": "7e90af26-0faa-40d4-f911-ed746d41aeed"
   },
   "outputs": [],
   "source": [
    "# Reportamos accuracy promedio y varianza para todas las configuraciones\n",
    "results = cv_re.cv_results_\n",
    "# 'mean_test_score' accuracy promedio\n",
    "# 'std_test_score' varianza\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_penalty', \n",
    "    'param_solver', \n",
    "    'param_C', \n",
    "    'param_random_state', \n",
    "    'param_max_iter', \n",
    "    'mean_test_score', \n",
    "    'std_test_score']]\\\n",
    "  .sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyjh6F_V7LwJ"
   },
   "source": [
    "#### Perceptrón multicapa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gOvRRt0V3rs"
   },
   "outputs": [],
   "source": [
    "# Perceptrón multicapa \n",
    "from sklearn import neural_network\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "param_grid = [{\n",
    "    'hidden_layer_sizes' : [10, 15],\n",
    "    'activation' : ['logistic', 'tanh', 'relu'],\n",
    "    'solver' : ['sgd'], \n",
    "    'alpha': [0.0001, 0.001, 0.01], \n",
    "    'batch_size' : [50, 20],\n",
    "    'random_state' : [43],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [0.001, 0.01, 0.1],\n",
    "    'shuffle' : [True],\n",
    "    'verbose' : [True],\n",
    "    'tol' : [0.0022, 0.01, 0.0001, 0.0008],\n",
    "    'max_iter' : [1000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsiO3lPzt15H",
    "outputId": "0fb00438-57d3-4a52-94ca-258e3602d069",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = neural_network.MLPClassifier()\n",
    "cv = GridSearchCV(model, param_grid, scoring='accuracy') # cv None (default) to use the default 5-fold cross validation\n",
    "cv.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjlDVneAzVtH"
   },
   "outputs": [],
   "source": [
    "cv.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YlxbsW6zkXl"
   },
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xN55ztizWzk"
   },
   "outputs": [],
   "source": [
    "# Reportamos accuracy promedio y varianza para todas las configuraciones\n",
    "results_neu = cv.cv_results_\n",
    "# 'mean_test_score' accuracy promedio\n",
    "# 'std_test_score' varianza\n",
    "df_neu = pd.DataFrame(results_neu)\n",
    "df_neu = df_neu.sort_values(by=['mean_test_score'], ascending=False)\n",
    "df_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACe5peQZS8DQ"
   },
   "outputs": [],
   "source": [
    "# Usamos neural_network\n",
    "from sklearn import neural_network\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = neural_network.MLPClassifier(\n",
    "    activation='tanh',\n",
    "    solver='sgd',\n",
    "    alpha=0.01, \n",
    "    hidden_layer_sizes=(10),\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.1,\n",
    "    batch_size=20,\n",
    "    random_state=43,\n",
    "    max_iter=1000,\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    "    tol=0.0001,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3FJYfnKTNAC"
   },
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCEwDfesUaZ8"
   },
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iu6tTU7JTr5p"
   },
   "outputs": [],
   "source": [
    "total_params = 0\n",
    "for case, name in zip(clf.coefs_, ('wi','bias')):\n",
    "    print(name, '=', np.size(case))\n",
    "    total_params += np.size(case)\n",
    "\n",
    "for case, name in zip(clf.intercepts_, ('wi','bias')):\n",
    "    print(name, '=', np.size(case))\n",
    "    total_params += np.size(case)\n",
    "\n",
    "print('total params = ', total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzW7VLYXUBC5"
   },
   "outputs": [],
   "source": [
    "np.round(np.exp(clf.predict_log_proba(x_train)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP8fyPqSTdWL"
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_train)\n",
    "print (f'Accuracy: {accuracy_score(y_train, predictions)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1S7I3Bzn993"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8j1zwDzyOFUs"
   },
   "outputs": [],
   "source": [
    "param_grid_rf = [{\n",
    "       'n_estimators': [ 180, 200,250],\n",
    "        'criterion'    : ['gini'],\n",
    "        'max_depth'    : [ 10, 20],\n",
    "        'max_features' : [3, 4, 5],\n",
    "        'n_jobs'       : [-1], # means using all processors\n",
    "        'random_state' : [0]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prk3OJrHd_0Z"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()\n",
    "cv = GridSearchCV(clf_rf, param_grid_rf, scoring='accuracy') \n",
    "cv.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNaVA8oc-DS8"
   },
   "outputs": [],
   "source": [
    "cv.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ny_QvyJK1iHb"
   },
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCC0OtrFiEmb"
   },
   "outputs": [],
   "source": [
    "# Reportamos accuracy promedio y varianza para todas las configuraciones\n",
    "results_rf = cv.cv_results_\n",
    "df_rf = pd.DataFrame(results_rf)\n",
    "df_rf = pd.DataFrame(results_rf).sort_values(by=['mean_test_score'], ascending=False)\n",
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgM_uvMRmciq"
   },
   "outputs": [],
   "source": [
    "cv.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGYxvNQqk4ze"
   },
   "outputs": [],
   "source": [
    "predictions = cv.predict(x_train)\n",
    "print (f'Accuracy: {accuracy_score(y_train, predictions)*100:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3BTAXeZK56f"
   },
   "source": [
    "#### DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbpgunGGK56g"
   },
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion' : ['gini', 'entropía', 'log_loss'],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \n",
    "    'min_samples_leaf': [1, 5, 10, 15, 20],\n",
    "    'random_state' : [0],\n",
    "    'ccp_alpha' : [0, 0.2, 0.6, 0.9, 1, 1.3, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnJfF_EuK56h"
   },
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "cv_dt = GridSearchCV(clf_dt, param_grid_dt, scoring='accuracy') # cv None (default) to use the default 5-fold cross validation\n",
    "cv_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOnLMgQvK56h"
   },
   "outputs": [],
   "source": [
    "cv_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTuyMzalK56h"
   },
   "outputs": [],
   "source": [
    "# Reportamos accuracy promedio y varianza para todas las configuraciones\n",
    "results_dt = cv_dt.cv_results_\n",
    "df_dt = pd.DataFrame(results_dt).sort_values(by=['mean_test_score'], ascending=False)\n",
    "df_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8x98B8IqLPmf"
   },
   "outputs": [],
   "source": [
    "cv_dt.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uaj28z8kLWaR"
   },
   "outputs": [],
   "source": [
    "predictions = cv_dt.predict(x_train)\n",
    "print (f'Accuracy: {accuracy_score(y_train, predictions)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kftLSaQBJcc6"
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gdzajl0hLlTm"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "gnb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QpmegBpPKs5"
   },
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(x_test)\n",
    "print(\"Métricas de validación para el mejor ajuste\")\n",
    "print(\"Accuracy = %s\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision = %s\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall = %s\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 = %s\" % f1_score(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, ['Cumplió_0', 'Incumplió_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5Fp7qudChEi"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpJO-PLkRF3E"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBALZpAbRVzu"
   },
   "outputs": [],
   "source": [
    "xgb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwp28xPHHyFN"
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=0)\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": range(1, 11, 2), # default 3\n",
    "    \"n_estimators\": range(50, 400, 50), # default 100   \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(model, params, scoring='accuracy') # cv None (default) to use the default 5-fold cross validation\n",
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jWtZxxK_0dX"
   },
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ug2gOxDqZRVY"
   },
   "outputs": [],
   "source": [
    "# Reportamos accuracy promedio y varianza para todas las configuraciones\n",
    "results = cv.cv_results_\n",
    "print(\"Best: %f using %s\" % (cv.best_score_, cv.best_params_))\n",
    "means = results['mean_test_score']\n",
    "stds = results['std_test_score']\n",
    "parameters = results['params']\n",
    "for mean, stdev, param in zip(means, stds, parameters):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGz9qyOtTiVC"
   },
   "outputs": [],
   "source": [
    "# Graficamos los resultados\n",
    "max_depth = range(1, 11, 2)\n",
    "n_estimators = range(50, 400, 50)\n",
    "scores = np.array(means).reshape(len(max_depth), len(n_estimators))\n",
    "for i, value in enumerate(max_depth):\n",
    "    plt.plot(n_estimators, scores[i], label='depth: ' + str(value))\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('n_estimators_vs_max_depth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhRPeXM6NP4H"
   },
   "outputs": [],
   "source": [
    "best_model = cv.best_estimator_\n",
    "# Métricas de validación\n",
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Métricas de validación para el mejor ajuste\")\n",
    "print(\"Accuracy = %s\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision = %s\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall = %s\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 = %s\" % f1_score(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, ['Cumplió_0', 'Incumplió_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDGsuT6JBbxI"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3deLjYPg9zu"
   },
   "outputs": [],
   "source": [
    "# Usamos SVM, clasificador lineal basado en una máquina de soporte compacto\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnHIbIYkCt7s"
   },
   "source": [
    "Grandes valores de C resultan en márgenes menores y pequeños valores de C resultan en márgenes más amplios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WawjqO46HOo"
   },
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for C in np.linspace(0.1, 100, 10):\n",
    "    # \"hinge\" is the standard SVM loss\n",
    "    clf = LinearSVC(C=C, loss=\"hinge\", random_state=26)\n",
    "    clf.fit(x_train, y_train.ravel())\n",
    "    predictions = clf.predict(x_train)\n",
    "    # calculamos el Accuracy\n",
    "    metrics.update({ 'C = '+str(round(C, 3)): (accuracy_score(y_train, predictions)*100) })\n",
    "\n",
    "print('\\n=== Accuracys ===\\n')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLuSLsGMHXqb"
   },
   "outputs": [],
   "source": [
    "print('=== Best Model ===\\n {}, Accuracy: {}'.format(\n",
    "        max(metrics, key=metrics.get), \n",
    "        max(metrics.values())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63uKAjUWlxwS"
   },
   "source": [
    "### Usamos VotingClassifier para los mejores modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3NApgnNEZ9t"
   },
   "source": [
    "Dentro de los modelos entrenados que mayor accuracy nos dieron, instanciamos los mismos con los mejores hiperparámetros, encontrados durante el entrenamiento,  para dar una predicción mejor con el Voting. El cual es un clasificador compuesto de varios clasificadores, en este caso usamos Random Forest (Bagging), perceptron multicapas con redes neuronales y xgboost (Boosting). El \"Voting\" simplemente elige la clase que tuvo \"más votos\" de los modelos que lo componen. El método de votacion elegido es \"soft\" que considera la probabilidad de los votos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW8roi6Yhr1z"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = RandomForestClassifier(\n",
    "    criterion = 'entropy',\n",
    "    n_jobs = -1,\n",
    "    max_depth = 20,\n",
    "    max_features = 5,\n",
    "    n_estimators = 200,\n",
    "    random_state = 0,\n",
    "    )\n",
    "\n",
    "clf2 = neural_network.MLPClassifier(\n",
    "    activation='tanh',\n",
    "    solver='sgd',\n",
    "    alpha=0.01, \n",
    "    hidden_layer_sizes=(10),\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.1,\n",
    "    batch_size=20,\n",
    "    random_state=43,\n",
    "    max_iter=1000,\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    "    tol=0.0001,\n",
    "    )\n",
    "clf3 = XGBClassifier(\n",
    "        max_depth= 7,\n",
    "        n_estimators = 150\n",
    "        )\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('RF', clf1), ('PM', clf2), ('NE', clf3)], voting='soft')\n",
    "eclf1.fit(x_train, y_train)\n",
    "predictions = eclf1.predict(x_test)\n",
    "print(classification_report(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxVQc26fcPxo"
   },
   "source": [
    "## Generar la salida para entregar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJoKXLS2JkxX"
   },
   "source": [
    "#### Imputacion y curacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSLHN_HycPxo"
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-j0lIePoCn0d"
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJVg3ZfHDA-s"
   },
   "outputs": [],
   "source": [
    "X_t = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK9rL1H7DA-s"
   },
   "outputs": [],
   "source": [
    "# Para la columna Destino cambiamos los nan por la moda \n",
    "dic_dest_t = {'TRAPPIST-1e' : 'Destination_TRAPPIST-1e',\n",
    "        '55 Cancri e' : 'Destination_55 Cancri e',\n",
    "        'PSO J318.5-22' : 'Destination_PSO J318.5-22',\n",
    "        np.nan : np.nan}\n",
    "X_t['Destination'] = X_t['Destination'].map(dic_dest_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uh5xBYMQDA-t"
   },
   "outputs": [],
   "source": [
    "# Hacemos un One Hot dividiendo las categorias de Destino\n",
    "x_dest_t = pd.get_dummies(X_t['Destination'])\n",
    "for i in range(len(x_dest_t)):\n",
    "    if (x_dest_t.iloc[i,0]+x_dest_t.iloc[i,1]+x_dest_t.iloc[i,2]) == 0:\n",
    "        x_dest_t.iloc[i,:] = x_dest_t.iloc[i,:].replace(0, np.nan)\n",
    "a = x_dest_t.columns\n",
    "X_t[a] = x_dest_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx0iq6FQDA-t"
   },
   "outputs": [],
   "source": [
    "# Para la columna HomePlanet cambiamos los nan por la moda \n",
    "dic_planet_t = {'Earth' : 'HomePlanet_Earth',\n",
    "              'Europa' : 'HomePlanet_Europa',\n",
    "              'Mars' : 'HomePlanet_Mars',\n",
    "              np.nan : np.nan}\n",
    "X_t['HomePlanet'] = X_t['HomePlanet'].map(dic_planet_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-H2lLXMMDA-t"
   },
   "outputs": [],
   "source": [
    "# Hacemos un One Hot dividiendo las categorias de HomePlanet\n",
    "x_home_t = pd.get_dummies(X_t['HomePlanet'])\n",
    "for i in range(len(x_home_t)):\n",
    "    if (x_home_t.iloc[i,0]+x_home_t.iloc[i,1]+x_home_t.iloc[i,2]) == 0:\n",
    "        x_home_t.iloc[i,:] = x_home_t.iloc[i,:].replace(0, np.nan)\n",
    "a = x_home_t.columns\n",
    "X_t[a] = x_home_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23AfGnQCDA-t"
   },
   "outputs": [],
   "source": [
    "# Separamos en tres columnas \"Cabin\"\n",
    "X_t[['Cabin_Deck','Cabin_Num','Cabin_Side']] = X_t['Cabin'].str.split('/',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKpmgRRqDA-t"
   },
   "outputs": [],
   "source": [
    "# Hacemos encodig de variables categoricas que tienen un cierto orden\n",
    "Label_cols = ['VIP', 'CryoSleep', 'Cabin_Deck', 'Cabin_Side' ]\n",
    "for col in Label_cols:\n",
    "    X_t[col] = LabelEncoder().fit_transform(X_t[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbVKC-y-DA-u"
   },
   "outputs": [],
   "source": [
    "# Volvemos a definir las variables nan para luego ser imputadas\n",
    "Label_col = ['VIP', 'CryoSleep', 'Cabin_Side' ]\n",
    "X_t[Label_col] = X_t[Label_col].replace(2, np.nan)\n",
    "X_t['Cabin_Deck'] = X_t['Cabin_Deck'].replace(8, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIXeILOhIFe3"
   },
   "outputs": [],
   "source": [
    "id_t = X_t['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPd913XlDA-u"
   },
   "outputs": [],
   "source": [
    "# Limpiamos el dataset antes de imputar los valores faltantes\n",
    "X_t = X_t.drop(['Cabin', 'Destination', 'HomePlanet', 'Name', 'PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXZo-O_jHc74"
   },
   "outputs": [],
   "source": [
    "X_t['Cabin_Num'] = X_t['Cabin_Num'].astype(float)\n",
    "X_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrLmdJ11Hc75"
   },
   "outputs": [],
   "source": [
    "# Estandarizamos y escalamos los valores antes de imputar\n",
    "x_names = X_t.columns\n",
    "scaler = StandardScaler()\n",
    "X_t = scaler.fit_transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p34B3rx3Hc75"
   },
   "outputs": [],
   "source": [
    "# Imputamos todos los valores con Knn Imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "X_knn_t = X_t.copy()\n",
    "knn_imputer = KNNImputer(n_neighbors=9, weights=\"uniform\")\n",
    "X_knn_t = knn_imputer.fit_transform(X_knn_t)\n",
    "\n",
    "# Volvemos a convertirlo en DF\n",
    "X_knn_t = pd.DataFrame(X_knn_t, columns=x_names)\n",
    "X_knn_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdLGruXgcPxp"
   },
   "source": [
    "### Generamos la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmye69-vcPxp"
   },
   "outputs": [],
   "source": [
    "# Realizamos la predicción con el conjunto de test\n",
    "test_pred = eclf1.predict(X_knn_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgOi256LcPxq"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(id_t, test_pred)), columns=[\"PassengerId\", \"Transported\"])\n",
    "submission.to_csv(\"sample_submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_k6BtP0licXX"
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GKYVMsnq2pq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download('sample_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AS_Entregable.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b65fc4380ac725e50a330b268a227bbdbe91bddfffbf68e5f7ce9848a2b8d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
